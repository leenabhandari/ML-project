Python 2.7.14 (v2.7.14:84471935ed, Sep 16 2017, 20:19:30) [MSC v.1500 32 bit (Intel)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> from pandas import read_csv
>>> import numpy as np
>>> from sklearn.neighbors import KNeighborsClassifier
>>> from sklearn import linear_model
>>> from sklearn.model_selection import train_test_split
>>> from sklearn import tree
>>> from sklearn.feature_extraction.text import CountVectorizer
>>> from sklearn.ensemble import RandomForestClassifier
>>> from sklearn.svm import SVC
>>> from sklearn.preprocessing import Imputer
>>> from sklearn.feature_extraction import FeatureHasher
>>> from sklearn.feature_extraction.text import HashingVectorizer
>>> from sklearn.model_selection import KFold
>>> from sklearn.model_selection import cross_val_score
>>> from sklearn.model_selection import cross_val_predict
>>> from sklearn import metrics
>>> import string
>>> data=read_csv('h1b_kaggle1.csv')
>>> ds=data.values
>>> X_data1=ds[:,6]
>>> Y_data=ds[:,1]
>>> imp=Imputer()
>>> X_trans=imp.fit_transform(X_data1.reshape(-1,1))
>>> model=tree.DecisionTreeClassifier()
>>> kfold = KFold(n_splits=10, random_state=7)
>>> predicted=cross_val_predict(model,X_trans,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8368334733389335
>>> model=RandomForestClassifier()
>>> predicted=cross_val_predict(model,X_trans,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8313332533301332

>>> full_time=ds[:,5]
>>>
>>> for i in range(full_time.size):
...  if full_time[i]=='Y':
...   full_time[i]=1
...  else:
...   full_time[i]=0
...
>>> model=tree.DecisionTreeClassifier()
>>> X_data2=np.c_[X_trans, full_time]
>>> predicted=cross_val_predict(model,X_data2,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8368334733389335
>>> model=RandomForestClassifier()
>>> predicted=cross_val_predict(model,X_data2,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8254530181207248

>>> lon=ds[:,9]>>> X_lon=imp.fit_transform(lon.reshape(-1,1))
>>> predicted=cross_val_predict(model,X_lon,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8720948837953518
>>> predicted[0:50]
array(['CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED'],
      dtype=object)
>>> X_data3=np.c_[X_trans, lon]
>>> X_data3=np.c_[X_trans, X_lon]
>>> predicted=cross_val_predict(model,X_lon,Y_data,cv=kfold)
>>> predicted=cross_val_predict(model,X_data3,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8321332853314133
>>> model=tree.DecisionTreeClassifier()
>>> predicted=cross_val_predict(model,X_data3,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.7948717948717948

>>> lat=ds[:,10]
>>> X_lat=imp.fit_transform(lat.reshape(-1,1))
>>> X_data4=np.c_[X_trans,X_lat]
>>> predicted=cross_val_predict(model,X_data3,Y_data,cv=kfold)
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8340733629345174
>>> model=tree.DecisionTreeClassifier()
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.7991119644785791

>>> X_data5=np.c_[X_trans,X_lon,X_lat]
>>> predicted=cross_val_predict(model,X_data5,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.7946917876715068
>>> model=RandomForestClassifier()
>>> predicted=cross_val_predict(model,X_data5,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8237729509180367

>>> ws=ds[:,8]
>>> ws=ws.astype(str)
>>> c=np.char.split(ws,',')
>>> d=[i[1] for i in c]
>>> hv = HashingVectorizer(n_features=10)
>>> X_ws=hv.transform(d).toarray()
>>> predicted=cross_val_predict(model,X_ws,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.875535021400856
>>> predicted[50:100]
array(['CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED'],
      dtype=object)
	  >>> X_data5=np.c_[X_trans,X_ws]
>>> predicted=cross_val_predict(model,X_data5,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.812332493299732
>>> model=tree.DecisionTreeClassifier()
>>> predicted=cross_val_predict(model,X_data5,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8157326293051722
>>> model=RandomForestClassifier()
>>> predicted=cross_val_predict(model,X_data6,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8292131685267411

>>> model=RandomForestClassifier(max_features='sqrt')
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8351934077363095
>>> model=RandomForestClassifier(max_features=0.2)
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8354934197367895
>>> predicted[0:50]
array(['CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED', 'DENIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED'], dtype=object)
	   
>>> model=tree.DecisionTreeClassifier()
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8012720508820352
>>> predicted[0:50]
array(['CERTIFIED', 'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED-WITHDRAWN', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED-WITHDRAWN', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN'], dtype=object)
	   
>>> model=RandomForestClassifier(max_features=0.2)
>>> model
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=0.2, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
>>> model=RandomForestClassifier(max_features=0.2,n_estimators=20)
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8388735549421977
>>> model=RandomForestClassifier(max_features=0.2,random_state=7)
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8361934477379095
>>> model=RandomForestClassifier(n_estimators=100,oob_score=True,n_jobs=-1,random_state=50,max_features="auto",min_samples_leaf=50)
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.875535021400856
>>> predicted[0:50]
array(['CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED'],
      dtype=object)
>>> model=RandomForestClassifier(n_estimators=100,oob_score=True,n_jobs=-1,random_state=50,max_features="auto")
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8363334533381335
>>> predicted[0:50]
array(['CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED'], dtype=object)
>>> model=RandomForestClassifier(oob_score=True,n_jobs=-1,random_state=50,max_features="auto",min_samples_leaf=50)
>>> model=RandomForestClassifier(oob_score=True,n_jobs=-1,random_state=50,max_features="auto")
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
C:\Users\leena_bhandari\AppData\Roaming\Python\Python27\site-packages\sklearn\ensemble\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.
  warn("Some inputs do not have OOB scores. "
C:\Users\leena_bhandari\AppData\Roaming\Python\Python27\site-packages\sklearn\ensemble\forest.py:458: RuntimeWarning: invalid value encountered in true_divide
  predictions[k].sum(axis=1)[:, np.newaxis])
>>> metrics.accuracy_score(Y_data, predicted)
0.8354534181367255
>>> model=RandomForestClassifier(n_jobs=-1,random_state=50,max_features="auto")
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8354534181367255
>>> predicted[0:25]
array(['CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN'], dtype=object)
>>> Y_data[0:25]
array(['CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN', 'WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN', 'WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED-WITHDRAWN'], dtype=object)
	   
>>> model=RandomForestClassifier(n_jobs=-1,random_state=50,n_estimators=1)
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.7936517460698428
>>> predicted[0:25]
array(['CERTIFIED', 'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'DENIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED-WITHDRAWN'], dtype=object)
>>> Y_data[0:25]
array(['CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN', 'WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN', 'WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED-WITHDRAWN'], dtype=object)
	   
>>> import matplotlib.pyplot as plt
>>> plt.boxplot(results)
{'boxes': [<matplotlib.lines.Line2D object at 0x0C1E3430>], 'fliers': [<matplotlib.lines.Line2D object at 0x0C1E3EF0>], 'medians': [<matplotlib.lines.Line2D object at 0x0C1E3CF0>], 'means': [], 'whiskers': [<matplotlib.lines.Line2D object at 0x0C1E33F0>, <matplotlib.lines.Line2D object at 0x0C1E3710>], 'caps': [<matplotlib.lines.Line2D object at 0x0C1E38F0>, <matplotlib.lines.Line2D object at 0x0C1E3AF0>]}
>>> plt.show
<function show at 0x0C190F70>
>>> plt.show()
>>> plt.hist(results)
(array([2., 1., 1., 3., 0., 1., 0., 0., 0., 2.]), array([0.7074 , 0.72858, 0.74976, 0.77094, 0.79212, 0.8133 , 0.83448,
       0.85566, 0.87684, 0.89802, 0.9192 ]), <a list of 10 Patch objects>)
>>> plt.show()

>>> X_train, X_test, Y_train, Y_test = train_test_split(X_data4, Y_data, test_size=0.10,random_state=7)
>>> model.fit(X_train,Y_train)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=-1,
            oob_score=False, random_state=50, verbose=0, warm_start=False)
>>> model.score(X_test,Y_test)
0.8294
>>> model.predict(X_test)[0:25]
array(['CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED'], dtype=object)
>>> Y_test[0:25]
array(['WITHDRAWN', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED-WITHDRAWN', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED'],
      dtype=object)
>>> model=RandomForestClassifier(n_jobs=-1,random_state=50,n_estimators=10)
>>> model.fit(X_train,Y_train)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
            oob_score=False, random_state=50, verbose=0, warm_start=False)
>>> model.score(X_test,Y_test)
0.8516
>>> model.predict(X_test)[0:25]
array(['CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'WITHDRAWN', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED'], dtype=object)
>>> Y_test[0:25]
array(['WITHDRAWN', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED-WITHDRAWN', 'CERTIFIED',
       'CERTIFIED', 'CERTIFIED-WITHDRAWN', 'CERTIFIED-WITHDRAWN',
       'CERTIFIED', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED',
       'CERTIFIED-WITHDRAWN', 'CERTIFIED', 'CERTIFIED', 'CERTIFIED'],
      dtype=object)
>>> model.score(X_test,Y_test)
0.8516

>>> plt.hist(Y_data)
(array([43775.,     0.,     0.,  3135.,     0.,     0.,  1284.,     0.,
           0.,  1804.]), array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]), <a list of 10 Patch objects>)
>>> plt.hist(predicted)
(array([44504.,     0.,     0.,  3245.,     0.,     0.,   854.,     0.,
           0.,  1395.]), array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]), <a list of 10 Patch objects>)
>>> plt.show()


Python 2.7.14 (v2.7.14:84471935ed, Sep 16 2017, 20:19:30) [MSC v.1500 32 bit (Intel)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> from pandas import read_csv
>>> import numpy as np
>>> from sklearn.neighbors import KNeighborsClassifier
>>> from sklearn import linear_model
>>> from sklearn.model_selection import train_test_split
>>> from sklearn import tree
>>> from sklearn.feature_extraction.text import CountVectorizer
>>> from sklearn.ensemble import RandomForestClassifier
>>> from sklearn.svm import SVC
>>> from sklearn.preprocessing import Imputer
>>> from sklearn.feature_extraction import FeatureHasher
>>> from sklearn.feature_extraction.text import HashingVectorizer
>>> from sklearn.model_selection import KFold
>>> from sklearn.model_selection import cross_val_score
>>> from sklearn.model_selection import cross_val_predict
>>> from sklearn import metrics
>>> import matplotlib.pyplot as plt
>>> import string
>>> data=read_csv('h1b_kaggle.csv')
>>> ds=data.values
>>> X_data1=ds[:,6]
>>> imp=Imputer()
>>> Y_data=ds[:,1]
>>> X_trans=imp.fit_transform(X_data1.reshape(-1,1))
>>> lat=ds[:,10]
>>> X_lat=imp.fit_transform(lat.reshape(-1,1))
>>> X_data4=np.c_[X_trans,X_lat]
>>> model=RandomForestClassifier(n_jobs=-1,random_state=50,n_estimators=1)
>>> kfold = KFold(n_splits=10, random_state=7)
>>> predicted=cross_val_predict(model,X_data4,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8214669447499349

>>> results = cross_val_score(model, X_trans, Y_data, cv=kfold,scoring='accuracy')
>>> results.mean()
0.8342132466493298
>>> results = cross_val_score(model, X_trans, Y_data, cv=kfold,scoring='f1_weighted')
>>> results.mean()
0.8061526144981764
>>> results = cross_val_score(model, X_trans, Y_data, cv=kfold,scoring='precision_weighted')
>>> results.mean()
0.7833350577546871
>>> results = cross_val_score(model, X_trans, Y_data, cv=kfold,scoring='recall_weighted')
>>> results.mean()
0.8366930866173234

>>> data=read_csv('h1b_sample3.csv')
>>> ds=data.values
>>> Y_data=ds[:,1]
>>> ws=ds[:,8]
>>> ws=ws.astype(str)
>>> c=np.char.split(ws,',')
>>> d=[i[1] for i in c]
>>> workstate=set(d)
>>> vec = CountVectorizer()
>>> vec.fit_transform(workstate)
<53x58 sparse matrix of type '<type 'numpy.int64'>'
        with 66 stored elements in Compressed Sparse Row format>
>>> X_ws=vec.transform(d).toarray()
>>> from sklearn.naive_bayes import MultinomialNB
>>> model=MultinomialNB()
>>> predicted=cross_val_predict(model,X_ws,Y_data,cv=kfold)
>>> metrics.accuracy_score(Y_data, predicted)
0.8290921213468163
